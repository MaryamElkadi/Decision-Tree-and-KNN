This project implements Tree Algorithms (specifically Decision Trees) and K-Nearest Neighbors (KNN) algorithm from scratch. Both of these algorithms are widely used in machine learning and artificial intelligence for classification and regression tasks.

The goal of this project is to understand the core concepts of these algorithms, implement them manually without relying on external libraries like scikit-learn, and explore their applications in solving real-world problems.

# Key Algorithms Implemented:
Decision Tree Algorithm:

A supervised learning algorithm used for both classification and regression tasks.
The decision tree splits data into branches based on feature values, aiming to increase homogeneity in each branch.
It uses criteria such as Gini Impurity, Entropy, or Mean Squared Error to decide the best split.
K-Nearest Neighbors (KNN) Algorithm:

A simple and effective supervised learning algorithm used for classification and regression.
It predicts the output for a new data point by finding the K nearest data points in the training set and taking a majority vote (classification) or averaging the output values (regression).
